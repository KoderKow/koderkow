---
title: tidymodels, rpart, and pengnuins
author: Kyle
date: '2020-08-17'
slug: tidymodels-rpart-and-pengnuins
categories:
  - Programming
tags:
  - Machine Learning
  - R
cover: /img/post_cover/tidymodels_rpart_penguins.png
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
---


<div id="TOC">
<ul>
<li><a href="#setup">Setup</a><ul>
<li><a href="#libraries">Libraries</a></li>
<li><a href="#data-preview">Data Preview</a></li>
<li><a href="#address-missing-data">Address Missing Data</a></li>
</ul></li>
<li><a href="#tidymodels-flow">tidymodels Flow</a><ul>
<li><a href="#split-the-data">Split the data</a></li>
<li><a href="#folds-cross-validation">5-Folds Cross-Validation</a></li>
<li><a href="#recipe">Recipe</a></li>
<li><a href="#creating-an-rpart-model-obejct">Creating an rpart Model Obejct</a></li>
<li><a href="#tune-grid">Tune Grid</a></li>
<li><a href="#workflow">Workflow</a></li>
<li><a href="#compute-performance-metrics">Compute Performance Metrics</a></li>
<li><a href="#selecting-the-best-model">Selecting the “Best” Model</a></li>
<li><a href="#evaluate-on-test-data">Evaluate on Test Data</a></li>
</ul></li>
<li><a href="#exploring-the-final-model">Exploring the Final Model</a><ul>
<li><a href="#variable-importance">Variable Importance</a></li>
<li><a href="#visualize-the-model">Visualize the Model</a></li>
<li><a href="#roc-auc-plots">ROC AUC Plots</a></li>
</ul></li>
<li><a href="#references">References</a><ul>
<li><a href="#packages">Packages</a></li>
<li><a href="#papers">Papers</a></li>
</ul></li>
</ul>
</div>

<p>I have seen posts on twitter about the <code>penguins</code> dataset from the <code>{palmerpenguins}</code> package. There has been interest within myself to test some <code>{tidymodels}</code> flows on it. As a self labeled “novice data scientist” I have decided to spend my free time on tree models. So this post will be quickly going over the tidymodels process and seeing how well we can predict the different classes of penguins using a simple decision tree!</p>
<hr />
<div id="setup" class="section level1">
<h1>Setup</h1>
<div id="libraries" class="section level2">
<h2>Libraries</h2>
<pre class="r"><code>library(palmerpenguins)
library(tidymodels)
library(skimr)
library(naniar)
library(vip)
library(rpart.plot)</code></pre>
</div>
<div id="data-preview" class="section level2">
<h2>Data Preview</h2>
<pre class="r"><code>penguins</code></pre>
<pre><code>## # A tibble: 344 x 8
##    species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g
##    &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;            &lt;int&gt;       &lt;int&gt;
##  1 Adelie  Torge…           39.1          18.7              181        3750
##  2 Adelie  Torge…           39.5          17.4              186        3800
##  3 Adelie  Torge…           40.3          18                195        3250
##  4 Adelie  Torge…           NA            NA                 NA          NA
##  5 Adelie  Torge…           36.7          19.3              193        3450
##  6 Adelie  Torge…           39.3          20.6              190        3650
##  7 Adelie  Torge…           38.9          17.8              181        3625
##  8 Adelie  Torge…           39.2          19.6              195        4675
##  9 Adelie  Torge…           34.1          18.1              193        3475
## 10 Adelie  Torge…           42            20.2              190        4250
## # … with 334 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;</code></pre>
<pre class="r"><code>skim(penguins)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">penguins</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">344</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">species</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">Ade: 152, Gen: 124, Chi: 68</td>
</tr>
<tr class="even">
<td align="left">island</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">Bis: 168, Dre: 124, Tor: 52</td>
</tr>
<tr class="odd">
<td align="left">sex</td>
<td align="right">11</td>
<td align="right">0.97</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">mal: 168, fem: 165</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bill_length_mm</td>
<td align="right">2</td>
<td align="right">0.99</td>
<td align="right">43.92</td>
<td align="right">5.46</td>
<td align="right">32.1</td>
<td align="right">39.23</td>
<td align="right">44.45</td>
<td align="right">48.5</td>
<td align="right">59.6</td>
<td align="left">▃▇▇▆▁</td>
</tr>
<tr class="even">
<td align="left">bill_depth_mm</td>
<td align="right">2</td>
<td align="right">0.99</td>
<td align="right">17.15</td>
<td align="right">1.97</td>
<td align="right">13.1</td>
<td align="right">15.60</td>
<td align="right">17.30</td>
<td align="right">18.7</td>
<td align="right">21.5</td>
<td align="left">▅▅▇▇▂</td>
</tr>
<tr class="odd">
<td align="left">flipper_length_mm</td>
<td align="right">2</td>
<td align="right">0.99</td>
<td align="right">200.92</td>
<td align="right">14.06</td>
<td align="right">172.0</td>
<td align="right">190.00</td>
<td align="right">197.00</td>
<td align="right">213.0</td>
<td align="right">231.0</td>
<td align="left">▂▇▃▅▂</td>
</tr>
<tr class="even">
<td align="left">body_mass_g</td>
<td align="right">2</td>
<td align="right">0.99</td>
<td align="right">4201.75</td>
<td align="right">801.95</td>
<td align="right">2700.0</td>
<td align="right">3550.00</td>
<td align="right">4050.00</td>
<td align="right">4750.0</td>
<td align="right">6300.0</td>
<td align="left">▃▇▆▃▂</td>
</tr>
<tr class="odd">
<td align="left">year</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">2008.03</td>
<td align="right">0.82</td>
<td align="right">2007.0</td>
<td align="right">2007.00</td>
<td align="right">2008.00</td>
<td align="right">2009.0</td>
<td align="right">2009.0</td>
<td align="left">▇▁▇▁▇</td>
</tr>
</tbody>
</table>
</div>
<div id="address-missing-data" class="section level2">
<h2>Address Missing Data</h2>
<pre class="r"><code>naniar::gg_miss_upset(penguins)</code></pre>
<p><img src="/post/2020-08-17-tidymodels-rpart-and-pengnuins.en_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Exploring the data itself will be a separate blog post. So I am opting to remove all rows containing missing data. This will remove a total of 11 rows.</p>
</div>
</div>
<div id="tidymodels-flow" class="section level1">
<h1>tidymodels Flow</h1>
<div id="split-the-data" class="section level2">
<h2>Split the data</h2>
<p>We will set a seed for reproducability. This means when we randomly split the data (80% to training, 20% to testing) that the results of the splits and upcoming cross validation folds will be the same for everyone who uses the same seed. It helps control the randomness.</p>
<pre class="r"><code>set.seed(1996)

data_split &lt;- 
  penguins %&gt;% 
  drop_na() %&gt;% 
  rsample::initial_split(
  data = ,
  prop = 0.8,
  strata = species
)

train_data &lt;- training(data_split)
test_data &lt;- testing(data_split)</code></pre>
</div>
<div id="folds-cross-validation" class="section level2">
<h2>5-Folds Cross-Validation</h2>
<p>I am choosing 5 folds because the <code>train_data</code> only has 268 rows of data, and this will allow the code to run faster. With a lower <span class="math inline">\(k\)</span> in cross validation, this generally means higher bias and lower variance because each fold will have more training training data. To help address the high bias, I will repeat the 5 fold process three times. In total I will have 15 folds to optimize my models parameters on.</p>
<pre class="r"><code>penguin_folds &lt;- vfold_cv(
  data = train_data,
  v = 5,
  repeats = 3,
  strata = species
)

penguin_folds</code></pre>
<pre><code>## #  5-fold cross-validation repeated 3 times using stratification 
## # A tibble: 15 x 3
##    splits           id      id2  
##    &lt;named list&gt;     &lt;chr&gt;   &lt;chr&gt;
##  1 &lt;split [213/55]&gt; Repeat1 Fold1
##  2 &lt;split [214/54]&gt; Repeat1 Fold2
##  3 &lt;split [215/53]&gt; Repeat1 Fold3
##  4 &lt;split [215/53]&gt; Repeat1 Fold4
##  5 &lt;split [215/53]&gt; Repeat1 Fold5
##  6 &lt;split [213/55]&gt; Repeat2 Fold1
##  7 &lt;split [214/54]&gt; Repeat2 Fold2
##  8 &lt;split [215/53]&gt; Repeat2 Fold3
##  9 &lt;split [215/53]&gt; Repeat2 Fold4
## 10 &lt;split [215/53]&gt; Repeat2 Fold5
## 11 &lt;split [213/55]&gt; Repeat3 Fold1
## 12 &lt;split [214/54]&gt; Repeat3 Fold2
## 13 &lt;split [215/53]&gt; Repeat3 Fold3
## 14 &lt;split [215/53]&gt; Repeat3 Fold4
## 15 &lt;split [215/53]&gt; Repeat3 Fold5</code></pre>
</div>
<div id="recipe" class="section level2">
<h2>Recipe</h2>
<p>Recipes in <code>{tidymodels}</code> is a description of what steps should be applied to a data set for model fitting. Here I am fitting a formula on the <code>train_data</code>. The <code>add_role(...)</code> function changes the role of a variable in the recipe. The <code>new_role</code> parameter can take anything we would like. There are key roles like <code>outcome</code> and <code>predictor</code>. Since I do not want to use the variable <code>year</code>, I will assign a random role of <code>&quot;dont_use&quot;</code> so that it will not be used during the model fitting process. Since I did not remove this column before hand and in the formula I specied <code>species ~ .</code>, that means every column. So this will avoid using that column.</p>
<pre class="r"><code>my_recipe &lt;-
  recipe(species ~ ., data = train_data) %&gt;% 
  add_role(year, new_role = &quot;dont_use&quot;)

my_recipe</code></pre>
<pre><code>## Data Recipe
## 
## Inputs:
## 
##       role #variables
##   dont_use          1
##    outcome          1
##  predictor          7</code></pre>
<p>We can see our model will have one outcome, <code>species</code>, and will use 7 predictors to generate that outcome.</p>
</div>
<div id="creating-an-rpart-model-obejct" class="section level2">
<h2>Creating an rpart Model Obejct</h2>
<p>rpart models have 3 parameters that can be optimized.</p>
<ol style="list-style-type: decimal">
<li><strong>cost_complexity</strong>: This is a parameter that helps “snips” or removes unnesseccary splits of the tree by using a formula (not showing the formula) where the cost complexity value helps determine if the split improves the model all around.</li>
<li><strong>tree_depth</strong>: Sets the maximum depth of any node of the final tree. A higher tree depth can result in overfitting depending on the dataset.</li>
<li><strong>min_n</strong>: The minimum number of observations that must exist in a node before a split in attempted. Setting a low min n can result in overfitting, depending on the dataset.</li>
</ol>
<p>How can we optimize this? tidymodels makes this extremely easy. First, we must specify the model using tidymodels framework. First we declare the type of model we want, decisition tree. Then the specific engine we want to use, rpart. Finally, the type of output.</p>
<p>Within the model we want to use, decisiton tree, is where we declare what we want to set the parameters to. But, we do not know what the best parameters are. So we will use <code>tune()</code> from the <code>{tune}</code> package to show the model pipeline we will be optimizing this parameter during the model fitting process.</p>
<pre class="r"><code>rpart_mod &lt;- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
  ) %&gt;% 
  set_engine(&quot;rpart&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)

rpart_mod</code></pre>
<pre><code>## Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   cost_complexity = tune()
##   tree_depth = tune()
##   min_n = tune()
## 
## Computational engine: rpart</code></pre>
</div>
<div id="tune-grid" class="section level2">
<h2>Tune Grid</h2>
<p>If you are familiar with your data and know what parameters will work best you can create your own grid. At the moment I am fascinated by these algorithms that tries its best to cover the parameter space given the number of different parameter combinations to test. For this post I will pick 5 so that the model training doesnt take too long. Each fold (we have 15) will be trained 5 times using the different combination of parameters that are generated using <code>grid_latin_hypercube()</code>.</p>
<pre class="r"><code>rpart_grid &lt;-
  grid_latin_hypercube(
  cost_complexity(),
  tree_depth(),
  min_n(),
  size = 5
  )

rpart_grid</code></pre>
<pre><code>## # A tibble: 5 x 3
##   cost_complexity tree_depth min_n
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;
## 1   0.0000372              4    10
## 2   0.00844                8     9
## 3   0.00000591             5    39
## 4   0.0000000716          13    32
## 5   0.00000000265         10    23</code></pre>
</div>
<div id="workflow" class="section level2">
<h2>Workflow</h2>
<p>A workflow is a container object that aggregates information required to fit and predict from a model. Here I will add our model to fit <code>rpart_mod</code> and the recipe we created <code>my_recipe</code>.</p>
<pre class="r"><code>rpart_wf &lt;-
  workflow() %&gt;%
  add_model(rpart_mod) %&gt;%
  add_recipe(my_recipe)

rpart_wf</code></pre>
<pre><code>## ══ Workflow ═══════════════════════════════════════
## Preprocessor: Recipe
## Model: decision_tree()
## 
## ── Preprocessor ───────────────────────────────────
## 0 Recipe Steps
## 
## ── Model ──────────────────────────────────────────
## Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   cost_complexity = tune()
##   tree_depth = tune()
##   min_n = tune()
## 
## Computational engine: rpart</code></pre>
</div>
<div id="compute-performance-metrics" class="section level2">
<h2>Compute Performance Metrics</h2>
<p>I will now use that workflow process to feed into <code>tune_grid()</code>. This function will compute a set of performance metrics (since we are doing classifcation we are looking at ROC AUC) for each of tuning parameter sets on each fold. For classification ROC AUC is used for evaluating models; aside from accuracy it takes sensitivity and specificity into account. Generally, ROC AUC is for a binary output. Here we have three so the method from <a href="https://link.springer.com/article/10.1023/A:1010920819831">Hand, Till, (2001)</a> will be used to compute the multi class ROC AUC. This will result in 15 rows, a row per fold.</p>
<p>If we do not specify the <code>metrics</code> parameter <code>tune_grid()</code> will return multiple different evaluation metrics. To simplify the process and we know what metric we want we will specify it.</p>
<pre class="r"><code>tree_res &lt;- 
  rpart_wf %&gt;% 
  tune_grid(
    resamples = penguin_folds,
    grid = rpart_grid,
    metrics = metric_set(roc_auc)
    )

tree_res</code></pre>
<pre><code>## #  5-fold cross-validation repeated 3 times using stratification 
## # A tibble: 15 x 5
##    splits           id      id2   .metrics         .notes          
##    &lt;named list&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          
##  1 &lt;split [213/55]&gt; Repeat1 Fold1 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  2 &lt;split [214/54]&gt; Repeat1 Fold2 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  3 &lt;split [215/53]&gt; Repeat1 Fold3 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  4 &lt;split [215/53]&gt; Repeat1 Fold4 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  5 &lt;split [215/53]&gt; Repeat1 Fold5 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  6 &lt;split [213/55]&gt; Repeat2 Fold1 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  7 &lt;split [214/54]&gt; Repeat2 Fold2 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  8 &lt;split [215/53]&gt; Repeat2 Fold3 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
##  9 &lt;split [215/53]&gt; Repeat2 Fold4 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
## 10 &lt;split [215/53]&gt; Repeat2 Fold5 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
## 11 &lt;split [213/55]&gt; Repeat3 Fold1 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
## 12 &lt;split [214/54]&gt; Repeat3 Fold2 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
## 13 &lt;split [215/53]&gt; Repeat3 Fold3 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
## 14 &lt;split [215/53]&gt; Repeat3 Fold4 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;
## 15 &lt;split [215/53]&gt; Repeat3 Fold5 &lt;tibble [5 × 6]&gt; &lt;tibble [0 × 1]&gt;</code></pre>
<p><code>collect_metrics()</code> will summarize the results per fold and show the results for each tuning parameter. Below shows each tuning parameter combination and its average ROC AUC average per fold. Since I specified a metric in the tune_grid this only shows ROC AUC. If I did not specify <code>metrics</code> then we would get back ROC AUC and Accuracy.</p>
<pre class="r"><code>tree_res %&gt;% 
  collect_metrics() </code></pre>
<pre><code>## # A tibble: 5 x 8
##   cost_complexity tree_depth min_n .metric .estimator  mean     n std_err
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1   0.00000000265         10    23 roc_auc hand_till  0.952    15 0.00775
## 2   0.0000000716          13    32 roc_auc hand_till  0.948    15 0.00731
## 3   0.00000591             5    39 roc_auc hand_till  0.948    15 0.00731
## 4   0.0000372              4    10 roc_auc hand_till  0.976    15 0.00328
## 5   0.00844                8     9 roc_auc hand_till  0.975    15 0.00324</code></pre>
</div>
<div id="selecting-the-best-model" class="section level2">
<h2>Selecting the “Best” Model</h2>
<p><code>show_best(&quot;roc_auc&quot;)</code> will arrange our metrics by the highest average.</p>
<pre class="r"><code>tree_res %&gt;%
  show_best()</code></pre>
<pre><code>## # A tibble: 5 x 8
##   cost_complexity tree_depth min_n .metric .estimator  mean     n std_err
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1   0.0000372              4    10 roc_auc hand_till  0.976    15 0.00328
## 2   0.00844                8     9 roc_auc hand_till  0.975    15 0.00324
## 3   0.00000000265         10    23 roc_auc hand_till  0.952    15 0.00775
## 4   0.0000000716          13    32 roc_auc hand_till  0.948    15 0.00731
## 5   0.00000591             5    39 roc_auc hand_till  0.948    15 0.00731</code></pre>
<p>To select the best performing parameters we can select them by using <code>select_best()</code>.</p>
<pre class="r"><code>best_rpart_params &lt;-
  tree_res %&gt;%
  select_best()

best_rpart_params</code></pre>
<pre><code>## # A tibble: 1 x 3
##   cost_complexity tree_depth min_n
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;
## 1       0.0000372          4    10</code></pre>
<p>Now that we have our “best” parameters for our model we can update our workflow.</p>
<pre class="r"><code>final_wf &lt;- 
  rpart_wf %&gt;% 
  finalize_workflow(best_rpart_params)</code></pre>
</div>
<div id="evaluate-on-test-data" class="section level2">
<h2>Evaluate on Test Data</h2>
<p>Finally, we can evaluate our final fit against the test data. Using the workflow and piping it into <code>last_fit(data_split)</code>, this process will take everything we have done and produce these results.</p>
<pre class="r"><code>final_fit &lt;- 
  final_wf %&gt;%
  last_fit(data_split) 

final_fit</code></pre>
<pre><code>## # # Monte Carlo cross-validation (0.8/0.2) with 1 resamples  
## # A tibble: 1 x 6
##   splits       id           .metrics      .notes       .predictions    .workflow
##   &lt;list&gt;       &lt;chr&gt;        &lt;list&gt;        &lt;list&gt;       &lt;list&gt;          &lt;list&gt;   
## 1 &lt;split [268… train/test … &lt;tibble [2 ×… &lt;tibble [0 … &lt;tibble [65 × … &lt;workflo…</code></pre>
<pre class="r"><code>final_fit %&gt;%
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy multiclass     0.923
## 2 roc_auc  hand_till      0.950</code></pre>
<p>95% ROC AUC! Great results for a simple tree algorithm.</p>
</div>
</div>
<div id="exploring-the-final-model" class="section level1">
<h1>Exploring the Final Model</h1>
<p>Using our final workflow we can fit the model using the training data.</p>
<pre class="r"><code>rpart_fit &lt;- 
  final_wf %&gt;%
  fit(data = train_data) 

rpart_fit </code></pre>
<pre><code>## ══ Workflow [trained] ═════════════════════════════
## Preprocessor: Recipe
## Model: decision_tree()
## 
## ── Preprocessor ───────────────────────────────────
## 0 Recipe Steps
## 
## ── Model ──────────────────────────────────────────
## n= 268 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
## 1) root 268 151 Adelie (0.43656716 0.20522388 0.35820896)  
##   2) flipper_length_mm&lt; 206.5 166  51 Adelie (0.69277108 0.30722892 0.00000000)  
##     4) bill_length_mm&lt; 43.35 116   3 Adelie (0.97413793 0.02586207 0.00000000) *
##     5) bill_length_mm&gt;=43.35 50   2 Chinstrap (0.04000000 0.96000000 0.00000000) *
##   3) flipper_length_mm&gt;=206.5 102   6 Gentoo (0.01960784 0.03921569 0.94117647)  
##     6) island=Dream,Torgersen 6   2 Chinstrap (0.33333333 0.66666667 0.00000000) *
##     7) island=Biscoe 96   0 Gentoo (0.00000000 0.00000000 1.00000000) *</code></pre>
<p>To extract the model from the workflow I will use <code>pull_workflow_fit()</code>.</p>
<pre class="r"><code>best_rpart &lt;-
  rpart_fit %&gt;% 
  pull_workflow_fit()

best_rpart</code></pre>
<pre><code>## parsnip model object
## 
## Fit time:  7ms 
## n= 268 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
## 1) root 268 151 Adelie (0.43656716 0.20522388 0.35820896)  
##   2) flipper_length_mm&lt; 206.5 166  51 Adelie (0.69277108 0.30722892 0.00000000)  
##     4) bill_length_mm&lt; 43.35 116   3 Adelie (0.97413793 0.02586207 0.00000000) *
##     5) bill_length_mm&gt;=43.35 50   2 Chinstrap (0.04000000 0.96000000 0.00000000) *
##   3) flipper_length_mm&gt;=206.5 102   6 Gentoo (0.01960784 0.03921569 0.94117647)  
##     6) island=Dream,Torgersen 6   2 Chinstrap (0.33333333 0.66666667 0.00000000) *
##     7) island=Biscoe 96   0 Gentoo (0.00000000 0.00000000 1.00000000) *</code></pre>
<div id="variable-importance" class="section level2">
<h2>Variable Importance</h2>
<p>With this model object I can creating variable importance plots using the <code>{vip}</code> package.</p>
<pre class="r"><code>vip(best_rpart)</code></pre>
<p><img src="/post/2020-08-17-tidymodels-rpart-and-pengnuins.en_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="visualize-the-model" class="section level2">
<h2>Visualize the Model</h2>
<p>The nice thing about rpart is that sense it is a singular decision tree we can easily visualize it. I will use the <code>{rpart.plot}</code> package for this visualization.</p>
<pre class="r"><code>rpart.plot(
  x =  best_rpart$fit,
  yesno = 2,
  type = 0,
  extra = 0
  )</code></pre>
<p><img src="/post/2020-08-17-tidymodels-rpart-and-pengnuins.en_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
<div id="roc-auc-plots" class="section level2">
<h2>ROC AUC Plots</h2>
<p>I can visual the ROC AUC curves using the <code>roc_curve</code> function. Since this is a multiclass output and the ROC AUC is calculated as an average of the pairwise ROC AUC per class, there will have to be a plot per class.</p>
<pre class="r"><code>penguin_roc_curves &lt;-
  final_fit %&gt;%
  collect_predictions() %&gt;% 
  roc_curve(species, .pred_Adelie:.pred_Gentoo)

penguin_roc_curves</code></pre>
<pre><code>## # A tibble: 16 x 4
##    .level    .threshold specificity sensitivity
##    &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1 Adelie     -Inf            0           1    
##  2 Adelie        0            0           1    
##  3 Adelie        0.0400       0.611       1    
##  4 Adelie        0.333        0.917       0.931
##  5 Adelie        0.974        0.944       0.931
##  6 Adelie      Inf            1           0    
##  7 Chinstrap  -Inf            0           1    
##  8 Chinstrap     0            0           1    
##  9 Chinstrap     0.0259       0.423       1    
## 10 Chinstrap     0.667        0.942       0.846
## 11 Chinstrap     0.96         0.942       0.769
## 12 Chinstrap   Inf            1           0    
## 13 Gentoo     -Inf            0           1    
## 14 Gentoo        0            0           1    
## 15 Gentoo        1            1           0.957
## 16 Gentoo      Inf            1           0</code></pre>
<pre class="r"><code>autoplot(penguin_roc_curves)</code></pre>
<p><img src="/post/2020-08-17-tidymodels-rpart-and-pengnuins.en_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<div id="packages" class="section level2">
<h2>Packages</h2>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">Brandon Greenwell, Brad Boehmke and Bernie Gray (2020). vip: Variable Importance Plots. R package version 0.2.1. <a href="https://CRAN.R-project.org/package=vip" class="uri">https://CRAN.R-project.org/package=vip</a></td>
</tr>
<tr class="even">
<td align="left">Elin Waring, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu and Shannon Ellis (2020). skimr: Compact and Flexible Summaries of Data. R package version 2.1.1. <a href="https://CRAN.R-project.org/package=skimr" class="uri">https://CRAN.R-project.org/package=skimr</a></td>
</tr>
<tr class="odd">
<td align="left">Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. <a href="https://allisonhorst.github.io/palmerpenguins/" class="uri">https://allisonhorst.github.io/palmerpenguins/</a></td>
</tr>
<tr class="even">
<td align="left">Max Kuhn and Hadley Wickham (2020). tidymodels: Easily Install and Load the ‘Tidymodels’ Packages. R package version 0.1.0. <a href="https://CRAN.R-project.org/package=tidymodels" class="uri">https://CRAN.R-project.org/package=tidymodels</a></td>
</tr>
<tr class="odd">
<td align="left">Nicholas Tierney, Di Cook, Miles McBain and Colin Fay (2020). naniar: Data Structures, Summaries, and Visualisations for Missing Data. R package version 0.5.1. <a href="https://CRAN.R-project.org/package=naniar" class="uri">https://CRAN.R-project.org/package=naniar</a></td>
</tr>
<tr class="even">
<td align="left">Stephen Milborrow (2019). rpart.plot: Plot ‘rpart’ Models: An Enhanced Version of ‘plot.rpart’. R package version 3.0.8. <a href="https://CRAN.R-project.org/package=rpart.plot" class="uri">https://CRAN.R-project.org/package=rpart.plot</a></td>
</tr>
</tbody>
</table>
</div>
<div id="papers" class="section level2">
<h2>Papers</h2>
<p>Hand, Till (2001). “A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems”. Machine Learning. Vol 45, Iss 2, pp 171-186.</p>
</div>
</div>
